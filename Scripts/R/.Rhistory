library(cluster)
library(factoextra)
library(dplyr)
library(datasets)
set.seed(20)
chicago.df <- read.csv("C:\\Users\\chira\\Documents\\IIT\\CourseWork\\Spring2020\\CSP554-BigDataTechnologies\\Project\\Data\\Crimes_-_2001_to_present.csv", header = T, stringsAsFactors = F)
#str(chicago.df)
sapply(chicago.df, function(x) sum(x=="" | is.na(x)))
sapply(chicago.df, function(x) sum(x=="" | is.na(x)))*100/nrow(chicago.df)
missing <- apply(chicago.df, 1, function(x) sum(x=="" | is.na(x)))/ncol(chicago.df)
head(missing[order(-missing)])
chicago.df <- chicago.df[missing == 0,]
jpeg('rplot1.jpg')
boxplot(chicago.df$X.Coordinate)
dev.off()
jpeg('rplot2.jpg')
boxplot(chicago.df$Y.Coordinate)
dev.off()
chicago.df <- filter(chicago.df, X.Coordinate != 0, Y.Coordinate != 0)
write.csv(chicago.df,"C:\\Users\\chira\\Documents\\IIT\\CourseWork\\Spring2020\\CSP554-BigDataTechnologies\\Project\\Data\\clean_data.csv")
library(ggplot2)
library(gplots)
crimes.by.season <- read.csv("C:\\Users\\chira\\Documents\\IIT\\CourseWork\\Spring2020\\CSP554-BigDataTechnologies\\Project\\Results\\PigResults\\Crimes_per_year.csv", header = F, stringsAsFactors = F)
colnames(crimes.by.season) <- c("Season", "Crime", "Freq")
crimes.by.season$Season <- as.factor(crimes.by.season$Season)
crimes.by.season$Crime <- as.factor(crimes.by.season$Crime)
crimes.by.season <- crimes.by.season[order(crimes.by.season$Season),]
test.res <- scale(xtabs(crimes.by.season$Freq~crimes.by.season$Season+crimes.by.season$Crime, data=crimes.by.season))
heatmap.2(test.res, scale = "none", col = bluered(100),
trace = "none", density.info = "none", key = T, dendrogram="none",srtCol=25)
locations.by.season <- read.csv("C:\\Users\\chira\\Documents\\IIT\\CourseWork\\Spring2020\\CSP554-BigDataTechnologies\\Project\\Results\\PigResults\\Count_Season.csv", header = F, stringsAsFactors = F)
colnames(locations.by.season) <- c("Season", "Location", "Freq")
locations.by.season$Season <- as.factor(locations.by.season$Season)
locations.by.season$Location <- as.factor(locations.by.season$Location)
locations.by.season <- locations.by.season[order(locations.by.season$Season),]
test.res <- scale(xtabs(locations.by.season$Freq~locations.by.season$Season+locations.by.season$Location, data=locations.by.season))
heatmap.2(test.res, scale = "none", col = bluered(100),
trace = "none", density.info = "none", key = T, dendrogram="none", Rowv = FALSE, Colv=FALSE)
battery.all <- read.csv("C:\\Users\\chira\\Documents\\IIT\\CourseWork\\Spring2020\\CSP554-BigDataTechnologies\\Project\\Results\\PigResults\\Count_Location.csv", header = F, stringsAsFactors = F)
colnames(battery.all) <- c("Location","Freq")
ggplot(battery.all, aes(x=battery.all$Location, y= battery.all$Freq))+
xlab("LOCATION")+
ylab("FREQUENCY") +
geom_bar(stat = "identity", fill="blue") +
coord_flip() +
labs(title="Most Battery Occurrences By Location",
subtitle="In City Of Chicago") +
theme(axis.text.x = element_text( vjust=0.6))
#Import all the required libraries
library(datasets)
library(SparkR)
library(cluster)
library(factoextra)
library(dplyr)
#Initialize and set sqlContext
sc <- sparkR.session(appName="SparkR-DataFrame-example")
sqlContext <- sparkRSQL.init(sc)
set.seed(20)
#Read the data and store it in a dataframe
chicago.df <- read.csv("C:\\Users\\chira\\Documents\\IIT\\CourseWork\\Spring2020\\CSP554-BigDataTechnologies\\Project\\Data\\clean_data.csv", header = T, stringsAsFactors = F)
#Store all the X-Coordinates in a vector
xcor <- chicago.df$X.Coordinate
#Store all the corresponding Y-Coordinates in a vector
ycor <- chicago.df$Y.Coordinate
#Store all the corresponding primary crime type in a vector
primary <- chicago.df$Primary.Type
#Create a dataframe called map.df with xcor, ycor and primary
map.df <- data.frame(xcor,ycor,primary)
head(map.df)
#Converting data.frame to DataFrame as spark.means require DataFrame
map <- createDataFrame(map.df)
#Converting data.frame to DataFrame as spark.means require DataFrame
map <- createDataFrame(map.df)
q()
